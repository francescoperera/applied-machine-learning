{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Neural networks as function approximators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://neuralnetworksanddeeplearning.com/chap4.html\n",
    "## The inspiration for the number of layers, and weights and biases comes from this link\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(x,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we define the weights and biases for each of our layers \n",
    "\n",
    "## Weights and biases for layer 1\n",
    "w1 = np.array([2,float(5)/3,float(5)/3,float(11)/3,float(5)/3]) #\n",
    "b1 = np.array([-2,float(-10)/3,float(-25)/3,-22,-15]) \n",
    "\n",
    "\n",
    "## weights and biases for layer 2\n",
    "w2 = np.array([1,-1,1,-1,1])\n",
    "b2 = 0\n",
    "\n",
    "# Input array of x's between 1 and 100\n",
    "x = np.linspace(0, 10, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputArr = []\n",
    "# Forward propagation\n",
    "for i in range(len(x)):\n",
    "    z1 = np.array(x[i]).dot(w1) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    a2 = a1.dot(w2) +b2\n",
    "    outputArr.append(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEZCAYAAACaWyIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg94vuXTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105be23c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105c08da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the input versus the output to generate the pride rock graph/ function\n",
    "plt.plot(x, outputArr)\n",
    "plt.axis([0, 10, -1, 6])\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.title('\"Pride Rock\"')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig(\"pride_rock.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Approximating images with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Describe the structure of the network. How many layers does this network have? What is the purpose of each layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network has 9 layers. The first layer, or the input layer, takes in a pixel as x and y. Then, there are 7 deep hidden layers, each of which has 20 ReLUs. Each layer is fully connected to the layer that comes before it, and the layer that comes after it. The final or 9th layer is the output layer, which is represented as a regression. The output layer has 3 neurons, each of which ouptuts a respective r,g,b value of the pixels used in the input. The hidden layers take the x, y pixel inputs, and transform the data for output the layer to operate on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) What does “Loss” mean here? What is the actual loss function? You may need to consult the source code, which is available on Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss here means the difference betweenthe approximated image and the input image. Looking at the source code in the \"convnet_layers_loss.js\" file in the backward function, which represents back propagation, gradient descent is computed. For each step and backward pass, the loss function is the negative log likelihood. \"// loss is the class negative log likelihood : return -Math.log(this.es[y]);\" Each calculation of loss is used for the gradient descent update: \"loss += 0.5*dy*dy;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Plot the loss over time, after letting it run for 5,000 iterations. How good does the network eventually get? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lossArr = [.09, .02, .02,  .016, .013, .012, .011, .011, .0104, .0102, .009, .0089, .0085, .0079, .0077, .0075, .0074, \\\n",
    "       .0073, .0070, .0067, .0065, .0065, .0063, .0064, .0064, .0061, .0061, .0062, .0061, .0057, .0052]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterArr = [40, 198, 299, 339, 499, 598, 698, 798, 898, 999, 1099, 1299, 1699, 1785, 1988, 2098, 2300, 2498, 2698, \\\n",
    "          2898, 3098, 3395, 3500, 3645, 3793, 4214, 4299, 4468, 4698, 4748, 5099]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.4/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEiSWv1/hJgnD4wuB48AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105eefda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iterArr, lossArr , s=20)\n",
    "plt.savefig(\"iter vs. loss.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that after 5,000 iterations, eventually the loss gets down to as low as .0052. It starts off at .1, and very quickly drops off to .02. Then, with each round of itertions it slowly approached .0052. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Can you make the network converge to a lower loss function by lowering the learning rate every 1,000 iterations? (Some learning rate schedules, for example, halve the learning rate every n iterations. Does this technique let the network converge to a lower training loss?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, if you lower the learning rate every 1000 iterations you do indeed see that the loss decreases more quickly, and that you end up with a lower loss rate overall after 5000 iterations. Starting with a learning rate of .01, at 40 iterations, the loss is .09. Then, at 1000 iteraions, I lowered the loss rate to .00398. At 2000 iterations with this new learning rate, the loss was already .0052, which is already lower than the loss rate we saw above. At 2000 iterations, I again lowered the learning rate to .0011, which led to a loss of .0039 at 3000 iterations. At 3000 iterations, I lowered the learning rate to .0007, which led to a loss of .0037 at 4000 iterations. At 4000 iterations I lowered the learning rate to .00039, which led to a loss of .0036 at 5000 iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Lesion study. The text box contains a small snippet of Javascript code that initializes the network. You can change the network structure by clicking the “Reload network” button, which simply evaluates the code. Let’s perform some brain surgery: Try commenting out each layer, one by one. Report some results: How many layers can you drop before the accuracy drops below a useful value? How few hidden units can you get away with before quality drops noticeably?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop 4 hidden layers before we notice a drop in accuracy. With 3 hidden layers (4 dropped),  the approximation of the image is still quite good, and the loss still converges to .0068 after 5000 iterations. However, if we remove 5 hidden layers, with only 2 hidden layers, the accuracy drops drastically to a loss rate of .012 after 5000 iterations, and the approxiation of the image is quite poor. If we leave only 1 hidden layer by removing 6 layers, the accuracy drops to a loss rate of .024. To put percents behind these, when we go from 7 inner layers to 5 inner layers, the accuracy drops by 9.6%, and when we go from 5 to 3 the accuracy drops by 19.3%. When we go from 3 to 2, that is when we see the largest drop in accuracy- a 76.5% reduction in accuracy. Then, when we go from 2 to 1, we see that that the accuracy rate drops by 100%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Try adding a few layers by copy+pasting lines in the network definition. Can you noticeably increase the accuracy of the network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added 2 more layers, and the network trains much more slowly, with a slight decrease in performance (.0053 vs. .0052) When I add in 2 additional layers (4 extra total), the training is painfully slow. Even if we decrease the learning rate with every 1000th iteration as we did above, the loss is still the same as when we have 4 less layers (.0036 versus .0036). Thus, by adding in extra layers, we do not see any increase in performance; in fact we see a decrease in performance since the nework takes much longer to train. For this particular data set, it seems that having between 5-8 middle layers is the appropriate amount of layers. You can have as little as 3 hidden layers, wihout really sacrificing performance and adding more than 7 does not increase performance. If you are optimizing for training time, you might choose less layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
