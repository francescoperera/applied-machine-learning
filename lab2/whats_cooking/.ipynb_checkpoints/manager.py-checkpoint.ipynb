{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy import interp\n",
    "from  matplotlib import pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics, preprocessing\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import operator\n",
    "import random\n",
    "from statistics import mean\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Read the data\n",
    "file = \"~/Documents/AML/HW2/train.json\"\n",
    "df = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To be used at the end\n",
    "cuisine_mapping = {0:\"greek\", 1:\"southern_us\", 2:\"filipino\", 3:\"indian\", 4:\"jamaican\", 5:\"spanish\", 6:\"itailian\",\\\n",
    "                  7: \"mexican\", 8:\"chinese\", 9:\"british\", 10:\"thai\", 11:\"vietnamese\", 12:\"cajun_creole\",\\\n",
    "                  13:\"brazilian\", 14:\"french\", 15:\"japanese\", 16:\"irish\", 17:\"korean\", \n",
    "                   18:\"moroccan\", 19:\"russian\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>1546</td>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>2673</td>\n",
       "      <td>2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>2646</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>1175</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>667</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>7838</td>\n",
       "      <td>7838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>1423</td>\n",
       "      <td>1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>830</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>6438</td>\n",
       "      <td>6438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>821</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>489</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>1539</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>825</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id ingredients\n",
       "             count       count\n",
       "cuisine                       \n",
       "brazilian      467         467\n",
       "british        804         804\n",
       "cajun_creole  1546        1546\n",
       "chinese       2673        2673\n",
       "filipino       755         755\n",
       "french        2646        2646\n",
       "greek         1175        1175\n",
       "indian        3003        3003\n",
       "irish          667         667\n",
       "italian       7838        7838\n",
       "jamaican       526         526\n",
       "japanese      1423        1423\n",
       "korean         830         830\n",
       "mexican       6438        6438\n",
       "moroccan       821         821\n",
       "russian        489         489\n",
       "southern_us   4320        4320\n",
       "spanish        989         989\n",
       "thai          1539        1539\n",
       "vietnamese     825         825"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The number of recipes per cuisine genre are represented below by aggregating the recipes  per cuisine\n",
    "numCuisineInst = df.groupby(['cuisine']).agg(['count'])\n",
    "numCuisineInst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The number of categories is 20\n",
    "len(numCuisineInst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Here we find that the number of rows is 39,774\n",
    "ingr_list = df['ingredients'].as_matrix()\n",
    "len(ingr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_frequency_ingredient_dict(dict_name, ingredients_list):\n",
    "    \"\"\"A method that acceps a matrix as input and returns a dictionary with the freuqency ounts\"\"\"\n",
    "    ### Here we loop through every ingredient, and create a dictionary \n",
    "    ## of the ingredients to get only the unique ingredients\n",
    "#     dict_name = dict()\n",
    "    for item in ingredients_list:\n",
    "        for ingredient in item:\n",
    "            if ingredient in dict_name:\n",
    "                dict_name[ingredient] +=1\n",
    "            else:\n",
    "                dict_name[ingredient] =1\n",
    "    return dict_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredient_dict = dict()\n",
    "ingredient_dict = create_frequency_ingredient_dict(ingredient_dict, ingr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6714"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingredient_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset consists of 39,774 rows of data, with 20 different categories of cuisines. However, we find that there is quite a bit of redundancy in the data, with only 6714 differnet unique ingredients. If we examine the ingredients even further, we see that the ingredients suffer from casing and phrasing issues. For example, there might be 'Romaine' and 'romaine', and phrases like \"Kraft Zesty Italian Dressing.\" So, go back and clean the ingredients so as to break apart any phrases into component words. 'Romaine Lettuce' becomes 'romaine', 'lettuce.' We also convert everything to lowercase, and drop any words that are 'a', 'the', 'of.' We then create a new dictionary from this and we find the number of unique ingredients to be about half as large at 3186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(matrix):\n",
    "    \"\"\" A function that accepts the matrix of ingredients as input. It loops through, splits any phrases into component\n",
    "        parts, and adds these to a new array. Also added to this array is the ingredient converted to lower case. \n",
    "        Anything that has 'a', 'the', 'and', 'of' is dropped. Then, we add this array to a new matrix. This returns\n",
    "        a matrix of lowercase, split, ingredients.\n",
    "    \"\"\"\n",
    "    new_list = []\n",
    "    for array in matrix:\n",
    "        row = []\n",
    "        for ingr in array:\n",
    "            if ' ' in ingr:\n",
    "#                 print(ingr)\n",
    "                new_ingr_split = ingr.split()\n",
    "#                 print(new_ingr_split)\n",
    "                for item in new_ingr_split:\n",
    "                    if item != 'the' and ingr != 'of' and ingr != 'and' and ingr != 'a':\n",
    "                        row.append(item.lower())\n",
    "            else:\n",
    "                row.append(ingr.lower())\n",
    "        new_list.append(row)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_matrix = clean_data(ingr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['romaine',\n",
       "  'lettuce',\n",
       "  'black',\n",
       "  'olives',\n",
       "  'grape',\n",
       "  'tomatoes',\n",
       "  'garlic',\n",
       "  'pepper',\n",
       "  'purple',\n",
       "  'onion',\n",
       "  'seasoning',\n",
       "  'garbanzo',\n",
       "  'beans',\n",
       "  'feta',\n",
       "  'cheese',\n",
       "  'crumbles']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_matrix[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_data_dict = dict()\n",
    "cleaned_data_dict = create_frequency_ingredient_dict(cleaned_data_dict, new_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3186"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to one hot encode the ingredients. To do this, we first convert all of the ingredients to numerical representations. Then we represent each of these numbers a binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## first, we create a dictionary of each item in the dataset, and map each ingredient as a key to a numerical value.\n",
    "def create_factorize_dict(dictName, matrix):\n",
    "    \"\"\"A method that takes as input a matrix, \n",
    "    and returns as output a dictionary with numerical representations of each ingredient.\"\"\"\n",
    "    dictName\n",
    "    k=0\n",
    "    for item in matrix:\n",
    "        for ingredient in item:\n",
    "            if ingredient not in dictName:\n",
    "                k+=1\n",
    "                dictName[ingredient] =k\n",
    "    return dictName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factorize_dict = dict()\n",
    "factorize_dict = create_factorize_dict(factorize_dict, new_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3186"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The lengths of the dictionary with frequency counts and numerical encoudings are the same\n",
    "len(factorize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now we go through the entire  matrix of ingredients, and replace each ingredient with the numerical value \n",
    "## In the dictionary we created above\n",
    "# def convert_to_factorized_list(factorized_dict_name, matrix, val_for_missing_ingredients):\n",
    "def convert_to_factorized_list(factorized_dict_name, matrix): \n",
    "    factorized_list = []\n",
    "    for array in matrix:\n",
    "        row = []\n",
    "        for x in array:\n",
    "            if x in factorized_dict_name:\n",
    "                num = factorized_dict_name[x]\n",
    "                row.append(num)\n",
    "#             else:\n",
    "#                 num = val_for_missing_ingredients\n",
    "#                 row.append(num)\n",
    "        factorized_list.append(row)\n",
    "    return factorized_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(blank_matrix, row_dim, col_dim, factorized_matrix_name): \n",
    "    blank_matrix = np.empty((row_dim, col_dim))\n",
    "    s = 0\n",
    "    while s < len(factorized_matrix_name):\n",
    "        for item in factorized_matrix_name[s]:\n",
    "            blank_matrix[s][item] = 1\n",
    "        s+=1\n",
    "    return blank_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "top10_ingred = sorted(cleaned_data_dict.items(), key=operator.itemgetter(1), reverse=True)[:10]\n",
    "top_ingred = top10_ingred[0][0]\n",
    "top_fact_val = factorize_dict[top_ingred]\n",
    "print(top_fact_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##We also need to factorize the cuisines. Thankfully, pandas has a built in function\n",
    "df['cuisine'] = pd.factorize(df['cuisine'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = np.asarray(new_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ ['romaine', 'lettuce', 'black', 'olives', 'grape', 'tomatoes', 'garlic', 'pepper', 'purple', 'onion', 'seasoning', 'garbanzo', 'beans', 'feta', 'cheese', 'crumbles'],\n",
       "       ['plain', 'flour', 'ground', 'pepper', 'salt', 'tomatoes', 'ground', 'black', 'pepper', 'thyme', 'eggs', 'green', 'tomatoes', 'yellow', 'corn', 'meal', 'milk', 'vegetable', 'oil']], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_matrix[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= m\n",
    "Y = df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##uses K fold to gather scores for each fold\n",
    "def evaluate(fold, val_for_missing_ingredients):\n",
    "    # Input: A tuple of (train, test) indices\n",
    "    train, test = fold\n",
    "    print(\"train: \", train, \" test:\", test)\n",
    "#     print(\"X[test]: \", X[test])\n",
    "    X_train_fact = convert_to_factorized_list(factorize_dict, X[train], val_for_missing_ingredients)\n",
    "    X_test_fact= convert_to_factorized_list(factorize_dict, X[test], val_for_missing_ingredients)\n",
    "   \n",
    "    X_train_one_hot = one_hot_encode(\"blank_matrix_train\", len(X_train_fact), \\\n",
    "                                        len(factorize_dict)+1, X_train_fact)\n",
    "    X_test_one_hot= one_hot_encode(\"blank_matrix_test\", \\\n",
    "                                       len(X_test_fact), len(factorize_dict)+1, X_test_fact)\n",
    "    print(\"len of x_train_fact\", len(X_train_one_hot))\n",
    "    print(\"len of y_train_fact\", len(Y[train]))\n",
    "    print(\"len of x_tst_fact\", len(X_test_one_hot))\n",
    "    print(\"len of y_test\", len(Y[test]))\n",
    "    print(\"len of fact_dict\", len(factorize_dict)+1)\n",
    "    return LogisticRegression().fit(X_train_one_hot, Y[train]) \\\n",
    "        .score(X_test_one_hot, Y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##uses K fold to gather scores for each fold\n",
    "def evaluate(fold):\n",
    "    # Input: A tuple of (train, test) indices\n",
    "    train, test = fold\n",
    "    print(\"train: \", train, \" test:\", test)\n",
    "#     print(\"X[test]: \", X[test])\n",
    "    X_train_fact = convert_to_factorized_list(factorize_dict, X[train])\n",
    "    X_test_fact= convert_to_factorized_list(factorize_dict, X[test])\n",
    "   \n",
    "    X_train_one_hot = one_hot_encode(\"blank_matrix_train\", len(X_train_fact), \\\n",
    "                                        len(factorize_dict)+1, X_train_fact)\n",
    "    X_test_one_hot= one_hot_encode(\"blank_matrix_test\", \\\n",
    "                                       len(X_test_fact), len(factorize_dict)+1, X_test_fact)\n",
    "    print(\"len of x_train_fact\", len(X_train_one_hot))\n",
    "    print(\"len of y_train_fact\", len(Y[train]))\n",
    "    print(\"len of x_tst_fact\", len(X_test_one_hot))\n",
    "    print(\"len of y_test\", len(Y[test]))\n",
    "    print(\"len of fact_dict\", len(factorize_dict)+1)\n",
    "    return LogisticRegression().fit(X_train_one_hot, Y[train]) \\\n",
    "        .score(X_test_one_hot, Y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_folds = cross_validation.KFold(len(X), n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## mean scores are\n",
    "# def get_scores(all_folds, val_for_missing_values):\n",
    "#     scores = []\n",
    "#     for fold in all_folds:\n",
    "#         scores.append(evaluate(fold, val_for_missing_values))\n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mean scores are\n",
    "def get_scores(all_folds)\n",
    "    scores = []\n",
    "    for fold in all_folds:\n",
    "        scores.append(evaluate(fold)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  [13258 13259 13260 ..., 39771 39772 39773]  test: [    0     1     2 ..., 13255 13256 13257]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n",
      "train:  [    0     1     2 ..., 39771 39772 39773]  test: [13258 13259 13260 ..., 26513 26514 26515]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n",
      "train:  [    0     1     2 ..., 26513 26514 26515]  test: [26516 26517 26518 ..., 39771 39772 39773]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n"
     ]
    }
   ],
   "source": [
    "performance = get_scores(all_folds,top_fact_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78229496656107"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Performance when using most frequent item to map items not found in dict\n",
    "from statistics import mean\n",
    "mean(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  [13258 13259 13260 ..., 39771 39772 39773]  test: [    0     1     2 ..., 13255 13256 13257]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n",
      "train:  [    0     1     2 ..., 39771 39772 39773]  test: [13258 13259 13260 ..., 26513 26514 26515]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n",
      "train:  [    0     1     2 ..., 26513 26514 26515]  test: [26516 26517 26518 ..., 39771 39772 39773]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n"
     ]
    }
   ],
   "source": [
    "##Performance when inserting 0 for items not found in dict\n",
    "performance2 = get_scores(all_folds,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78229496656107"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(performance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.78405491024287222, 0.78050988082667072, 0.78232010861366719]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  [13258 13259 13260 ..., 39771 39772 39773]  test: [    0     1     2 ..., 13255 13256 13257]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n",
      "train:  [    0     1     2 ..., 39771 39772 39773]  test: [13258 13259 13260 ..., 26513 26514 26515]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n",
      "train:  [    0     1     2 ..., 26513 26514 26515]  test: [26516 26517 26518 ..., 39771 39772 39773]\n",
      "len of x_train_fact 26516\n",
      "len of y_train_fact 26516\n",
      "len of x_tst_fact 13258\n",
      "len of y_test 13258\n",
      "len of fact_dict 3187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perfomance3 = get_scores(all_folds,random.choice(np.arange(0, len(factorize_dict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78229496656107"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## performance when randomly choosing a number to map to\n",
    "mean(perfomance3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Peformance when ignoring items not found in dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
