{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from itertools import count\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "import heapq\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import itertools\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image features cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanImageFeatures(filename):\n",
    "    features_df = pd.read_csv(filename, header =None)\n",
    "    split= features_df[0].str.split('/', 1, expand=True)\n",
    "    split2= split[1].str.split('.', 1, expand=True).drop([1], axis=1)\n",
    "    split2 = split2.rename(columns={0: \"index\"})\n",
    "    result = pd.concat([split2, features_df], axis=1)\n",
    "    result[\"index\"] = result[\"index\"].astype(float)\n",
    "    result = result.sort([\"index\"], ascending = 1)\n",
    "    imageDF = result.drop([\"index\", 0], axis=1)\n",
    "    softMaxDF = imageDF.apply(softmax, axis = 1)\n",
    "    return softMaxDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softMaxDF = cleanImageFeatures(\"../../final/data/features_train/features_resnet1000_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>4.690518e-07</td>\n",
       "      <td>1.578537e-06</td>\n",
       "      <td>9.328652e-05</td>\n",
       "      <td>1.534686e-05</td>\n",
       "      <td>3.026676e-05</td>\n",
       "      <td>1.125796e-05</td>\n",
       "      <td>1.864312e-06</td>\n",
       "      <td>1.318828e-05</td>\n",
       "      <td>7.214815e-07</td>\n",
       "      <td>2.772918e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.840809e-07</td>\n",
       "      <td>7.580978e-07</td>\n",
       "      <td>9.254151e-07</td>\n",
       "      <td>1.273813e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.889290e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>4.467573e-06</td>\n",
       "      <td>5.971302e-06</td>\n",
       "      <td>1.529179e-08</td>\n",
       "      <td>5.232497e-08</td>\n",
       "      <td>1.308296e-07</td>\n",
       "      <td>7.229350e-07</td>\n",
       "      <td>3.534124e-08</td>\n",
       "      <td>4.790586e-08</td>\n",
       "      <td>5.903218e-07</td>\n",
       "      <td>1.991982e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.191289e-07</td>\n",
       "      <td>4.550022e-07</td>\n",
       "      <td>9.496120e-07</td>\n",
       "      <td>3.101960e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.111328e-06</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8598</th>\n",
       "      <td>2.713387e-06</td>\n",
       "      <td>1.392071e-06</td>\n",
       "      <td>7.225265e-07</td>\n",
       "      <td>7.912383e-07</td>\n",
       "      <td>1.237272e-05</td>\n",
       "      <td>1.460976e-05</td>\n",
       "      <td>8.789415e-07</td>\n",
       "      <td>2.602356e-06</td>\n",
       "      <td>1.653813e-06</td>\n",
       "      <td>8.984420e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.461717e-08</td>\n",
       "      <td>1.228283e-07</td>\n",
       "      <td>1.717705e-06</td>\n",
       "      <td>7.607935e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>3.585788e-07</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9239</th>\n",
       "      <td>1.217408e-04</td>\n",
       "      <td>1.302585e-05</td>\n",
       "      <td>3.159552e-06</td>\n",
       "      <td>4.374011e-06</td>\n",
       "      <td>2.742091e-05</td>\n",
       "      <td>1.317878e-05</td>\n",
       "      <td>1.326868e-06</td>\n",
       "      <td>3.183221e-06</td>\n",
       "      <td>2.773982e-06</td>\n",
       "      <td>1.025100e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>3.802230e-06</td>\n",
       "      <td>2.056403e-05</td>\n",
       "      <td>1.319618e-06</td>\n",
       "      <td>7.643639e-06</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>2.643319e-06</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8410</th>\n",
       "      <td>1.894039e-05</td>\n",
       "      <td>9.904532e-07</td>\n",
       "      <td>5.770281e-06</td>\n",
       "      <td>4.656676e-05</td>\n",
       "      <td>4.786610e-05</td>\n",
       "      <td>1.612394e-06</td>\n",
       "      <td>1.038364e-06</td>\n",
       "      <td>7.940026e-05</td>\n",
       "      <td>2.456297e-05</td>\n",
       "      <td>3.643926e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5.374604e-07</td>\n",
       "      <td>1.301471e-06</td>\n",
       "      <td>9.156633e-07</td>\n",
       "      <td>8.342256e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.147001e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1             2             3             4             5     \\\n",
       "6643  4.690518e-07  1.578537e-06  9.328652e-05  1.534686e-05  3.026676e-05   \n",
       "2273  4.467573e-06  5.971302e-06  1.529179e-08  5.232497e-08  1.308296e-07   \n",
       "8598  2.713387e-06  1.392071e-06  7.225265e-07  7.912383e-07  1.237272e-05   \n",
       "9239  1.217408e-04  1.302585e-05  3.159552e-06  4.374011e-06  2.742091e-05   \n",
       "8410  1.894039e-05  9.904532e-07  5.770281e-06  4.656676e-05  4.786610e-05   \n",
       "\n",
       "              6             7             8             9             10    \\\n",
       "6643  1.125796e-05  1.864312e-06  1.318828e-05  7.214815e-07  2.772918e-05   \n",
       "2273  7.229350e-07  3.534124e-08  4.790586e-08  5.903218e-07  1.991982e-07   \n",
       "8598  1.460976e-05  8.789415e-07  2.602356e-06  1.653813e-06  8.984420e-07   \n",
       "9239  1.317878e-05  1.326868e-06  3.183221e-06  2.773982e-06  1.025100e-05   \n",
       "8410  1.612394e-06  1.038364e-06  7.940026e-05  2.456297e-05  3.643926e-05   \n",
       "\n",
       "        ...         991           992           993           994   \\\n",
       "6643    ...     0.000006  3.840809e-07  7.580978e-07  9.254151e-07   \n",
       "2273    ...     0.000002  4.191289e-07  4.550022e-07  9.496120e-07   \n",
       "8598    ...     0.000002  9.461717e-08  1.228283e-07  1.717705e-06   \n",
       "9239    ...     0.000224  3.802230e-06  2.056403e-05  1.319618e-06   \n",
       "8410    ...     0.000010  5.374604e-07  1.301471e-06  9.156633e-07   \n",
       "\n",
       "              995       996       997           998       999       1000  \n",
       "6643  1.273813e-06  0.000006  0.000005  5.889290e-07  0.000011  0.000037  \n",
       "2273  3.101960e-06  0.000009  0.000080  1.111328e-06  0.000136  0.000001  \n",
       "8598  7.607935e-07  0.000003  0.000017  3.585788e-07  0.000026  0.000007  \n",
       "9239  7.643639e-06  0.000170  0.000042  2.643319e-06  0.000302  0.000328  \n",
       "8410  8.342256e-07  0.000005  0.000005  3.147001e-07  0.000028  0.000118  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softMaxDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files, set train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptionTrainFolder = \"../../final/data/descriptions_train\"\n",
    "featuresTrainFolder = \"../../final/data/features_train\"\n",
    "imagesTrainFolder = \"../../final/data/images_train\"\n",
    "tagsTrainFolder = \"../../final/data/tags_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptionTestFolder = \"../../final/data/descriptions_test\"\n",
    "featureTestFolder = \"../../final/data/features_test\"\n",
    "imagesTestFolder = \"../../final/data/images_test\"\n",
    "tagsTestFolder = \"../../final/data/tags_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numTrain = 10000\n",
    "numTest = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTagsFile(fileName):\n",
    "    tags = []\n",
    "    f = open(fileName,\"r\")\n",
    "    for line in f:\n",
    "        line = line.split(\":\") # possibly also consider using the keys in each line(vehicle,outdoor etc..)\n",
    "        tag = line[-1].replace(\"\\n\",\"\")\n",
    "        tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "def readDescriptionFile(fileName):\n",
    "    desc = []\n",
    "    f = open(fileName,\"r\")\n",
    "    for line in f:\n",
    "        noPuncSentence = stripPunctuation(line)\n",
    "        desc.append(noPuncSentence)\n",
    "    return desc\n",
    "\n",
    "def stripPunctuation(s):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    return regex.sub(' ', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTagDict(num,tagFolder):\n",
    "    tags = {}\n",
    "    for n in range(num):\n",
    "        f = tagFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileTags = readTagsFile(f)\n",
    "        #newTags = stemTags(fileTags)\n",
    "        for tag in fileTags:\n",
    "            if str(tag) not in tags.keys():\n",
    "                tags[str(tag)] = 0\n",
    "            else:\n",
    "                tags[str(tag)] +=1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagDict = getTagDict(numTrain,tagsTrainFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'giraffe': 217, 'airplane': 221, 'toilet': 287, 'baseball glove': 198, 'mouse': 158, 'dining table': 959, 'apple': 106, 'bicycle': 284, 'train': 330, 'bottle': 707, 'suitcase': 188, 'bowl': 592, 'teddy bear': 183, 'fire hydrant': 151, 'clock': 441, 'surfboard': 321, 'cake': 216, 'fork': 267, 'umbrella': 357, 'remote': 239, 'car': 1021, 'zebra': 168, 'potted plant': 356, 'stop sign': 141, 'bear': 86, 'hot dog': 121, 'frisbee': 194, 'sports ball': 339, 'person': 5322, 'toaster': 23, 'traffic light': 327, 'bird': 305, 'toothbrush': 79, 'baseball bat': 193, 'motorcycle': 327, 'tv': 351, 'cup': 746, 'vase': 310, 'cell phone': 436, 'tennis racket': 293, 'skateboard': 256, 'cat': 354, 'horse': 218, 'hair drier': 11, 'boat': 276, 'spoon': 292, 'refrigerator': 204, 'book': 446, 'backpack': 428, 'handbag': 597, 'cow': 177, 'kite': 200, 'sandwich': 207, 'oven': 246, 'laptop': 303, 'wine glass': 214, 'dog': 391, 'parking meter': 57, 'keyboard': 169, 'elephant': 178, 'bench': 475, 'bed': 314, 'carrot': 138, 'banana': 169, 'sink': 389, 'snowboard': 128, 'sheep': 122, 'truck': 498, 'chair': 1029, 'couch': 344, 'knife': 331, 'orange': 130, 'broccoli': 162, 'scissors': 72, 'microwave': 112, 'skis': 237, 'bus': 330, 'donut': 117, 'tie': 305, 'pizza': 265}\n"
     ]
    }
   ],
   "source": [
    "print (tagDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['giraffe', 'airplane', 'toilet', 'baseball glove', 'mouse', 'dining table', 'apple', 'bicycle', 'train', 'bottle', 'suitcase', 'bowl', 'teddy bear', 'fire hydrant', 'clock', 'surfboard', 'cake', 'fork', 'umbrella', 'remote', 'car', 'zebra', 'potted plant', 'stop sign', 'bear', 'hot dog', 'frisbee', 'sports ball', 'person', 'toaster', 'traffic light', 'bird', 'toothbrush', 'baseball bat', 'motorcycle', 'tv', 'cup', 'vase', 'cell phone', 'tennis racket', 'skateboard', 'cat', 'horse', 'hair drier', 'boat', 'spoon', 'refrigerator', 'book', 'backpack', 'handbag', 'cow', 'kite', 'sandwich', 'oven', 'laptop', 'wine glass', 'dog', 'parking meter', 'keyboard', 'elephant', 'bench', 'bed', 'carrot', 'banana', 'sink', 'snowboard', 'sheep', 'truck', 'chair', 'couch', 'knife', 'orange', 'broccoli', 'scissors', 'microwave', 'skis', 'bus', 'donut', 'tie', 'pizza'])\n"
     ]
    }
   ],
   "source": [
    "print (tagDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([217, 221, 287, 198, 158, 959, 106, 284, 330, 707, 188, 592, 183, 151, 441, 321, 216, 267, 357, 239, 1021, 168, 356, 141, 86, 121, 194, 339, 5322, 23, 327, 305, 79, 193, 327, 351, 746, 310, 436, 293, 256, 354, 218, 11, 276, 292, 204, 446, 428, 597, 177, 200, 207, 246, 303, 214, 391, 57, 169, 178, 475, 314, 138, 169, 389, 128, 122, 498, 1029, 344, 331, 130, 162, 72, 112, 237, 330, 117, 305, 265])\n"
     ]
    }
   ],
   "source": [
    "print (tagDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createBag(num,tagFolder):\n",
    "    tags = {}\n",
    "    for n in range(num):\n",
    "        f = tagFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileTags = readTagsFile(f)\n",
    "        #newTags = stemTags(fileTags) - maybe add stemming - Francesco\n",
    "        for t in fileTags:\n",
    "            if t not in tags.keys():\n",
    "                tags[t] = 0\n",
    "    return tags\n",
    "\n",
    "def stemTags(lst):\n",
    "    newTags = []\n",
    "    for word in lst:\n",
    "        stem = str(PorterStemmer().stem(word))\n",
    "        newTags.append(stem)\n",
    "    return newTags\n",
    "\n",
    "def indexBag(bag):\n",
    "    idx = 0\n",
    "    for tag in bag.keys():\n",
    "        bag[tag] = idx\n",
    "        idx+=1\n",
    "    return bag\n",
    "\n",
    "def getTagVectors(num,tagFolder,indexedTagBag):\n",
    "    tagVecs = np.zeros((num,len(indexedTagBag.keys()))) #2D Array of size (file number, len(indexedBagTag.keys))\n",
    "    for n in range(num):\n",
    "        f = tagFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileTags = readTagsFile(f)\n",
    "        #newTags = stemTags(fileTags) - maybe add stemming - Francesco\n",
    "        for tag in fileTags:\n",
    "            if tag in indexedTagBag.keys():\n",
    "                tagVecs[n,indexedTagBag[tag]] = 1\n",
    "            else:\n",
    "                print (str(tag) + \" is not in the tag BOW\")\n",
    "    return pd.DataFrame(tagVecs,columns = indexedTagBag.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagBag = createBag(numTrain,tagsTrainFolder)\n",
    "indexedTagBag = indexBag(tagBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagVectors = getTagVectors(numTrain,tagsTrainFolder,indexedTagBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 80)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagVectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStopWords():\n",
    "    return set(stopwords.words(\"english\"))\n",
    "\n",
    "def lowerCase(x):\n",
    "    return x.lower()\n",
    "\n",
    "def lemmatize(lmt,x):\n",
    "    return lmt.lemmatize(x)\n",
    "\n",
    "def getPos(line):\n",
    "    return pos_tag(line)\n",
    "\n",
    "def tokenize(line):\n",
    "    return line.split()\n",
    "\n",
    "def stripPunctuation(s):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    return regex.sub(' ', s)\n",
    "\n",
    "def stemmer(line):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmedLine = []\n",
    "    for word in line:\n",
    "        #if pos == \"NN\": #only stem nouns\n",
    "        stem = stemmer.stem(word)\n",
    "        stemmedLine.append(stem)\n",
    "    return stemmedLine \n",
    "\n",
    "def stemmedDescriptions(lst):\n",
    "    stemmedDescriptions = []\n",
    "    for line in lst:\n",
    "        tokenizedLine = tokenize(line)\n",
    "        stemmedDescriptions.append(stemmer(tokenizedLine))\n",
    "    return stemmedDescriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createBag(num,descFolder):\n",
    "    bag = {}\n",
    "    stopWords = getStopWords()\n",
    "    for n in range(num):\n",
    "        f = descFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileDescriptions = readDescriptionFile(f) #2D Array\n",
    "        stemDescriptions = stemmedDescriptions(fileDescriptions) #applying stemming so to aggregate similar words\n",
    "        for desc in stemDescriptions:\n",
    "            for word in desc:\n",
    "                lowerWord = lowerCase(word)\n",
    "                if str(lowerWord) not in bag.keys() and str(lowerWord) != \"\" and str(lowerWord) not in stopWords:\n",
    "                    bag[str(lowerWord)] = 0 \n",
    "    return bag\n",
    "\n",
    "def indexBag(bag):\n",
    "    idx = 0\n",
    "    for tag in bag.keys():\n",
    "        bag[tag] = idx\n",
    "        idx+=1\n",
    "    return bag\n",
    "\n",
    "def binaryVectorizeDescriptions(num,descFolder,indexedDescBag):\n",
    "    stopWords = getStopWords()\n",
    "    featureVectorList = []\n",
    "    for n in range(num):\n",
    "        imageTagVec = [0.0 for tag in range(len(indexedDescBag.keys()))]\n",
    "        f = descFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileDescriptions = readDescriptionFile(f) #2D Array\n",
    "        stemDescriptions = stemmedDescriptions(fileDescriptions) #applying stemming so to aggregate similar words\n",
    "        for desc in stemDescriptions:\n",
    "            for word in desc:\n",
    "                lowerWord = lowerCase(word)\n",
    "                if str(lowerWord) in indexedDescBag.keys() and str(lowerWord) != \"\" and str(lowerWord) not in stopWords:\n",
    "                    imageTagVec[indexedDescBag[str(lowerWord)]] +=1.0\n",
    "        featureVectorList.append(imageTagVec)\n",
    "    return pd.DataFrame(featureVectorList,columns = indexedDescBag.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descBag = createBag(numTrain,descriptionTrainFolder)\n",
    "indexedDescBag = indexBag(descBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descVectors = binaryVectorizeDescriptions(numTrain,descriptionTrainFolder,indexedDescBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizedDescVector = descVectors.div(descVectors.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6456)\n"
     ]
    }
   ],
   "source": [
    "print (normalizedDescVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allFeatures = pd.concat([normalizedDescVector, softMaxDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allFeaturesNonNorm =pd.concat([descVectors, softMaxDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corner</th>\n",
       "      <th>overheard</th>\n",
       "      <th>size</th>\n",
       "      <th>lazili</th>\n",
       "      <th>camersa</th>\n",
       "      <th>apia</th>\n",
       "      <th>bumper</th>\n",
       "      <th>world</th>\n",
       "      <th>greenish</th>\n",
       "      <th>fom</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.147876e-09</td>\n",
       "      <td>7.795882e-07</td>\n",
       "      <td>2.137072e-08</td>\n",
       "      <td>4.536942e-07</td>\n",
       "      <td>2.348028e-07</td>\n",
       "      <td>1.146491e-06</td>\n",
       "      <td>1.363482e-06</td>\n",
       "      <td>1.078203e-08</td>\n",
       "      <td>1.252444e-07</td>\n",
       "      <td>3.330733e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.153486e-06</td>\n",
       "      <td>2.155777e-08</td>\n",
       "      <td>7.707900e-08</td>\n",
       "      <td>1.716825e-08</td>\n",
       "      <td>6.402719e-08</td>\n",
       "      <td>3.399505e-07</td>\n",
       "      <td>2.291550e-07</td>\n",
       "      <td>8.842370e-09</td>\n",
       "      <td>4.936724e-07</td>\n",
       "      <td>4.335200e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.043387e-07</td>\n",
       "      <td>4.378452e-07</td>\n",
       "      <td>3.107051e-07</td>\n",
       "      <td>4.795648e-07</td>\n",
       "      <td>1.099367e-06</td>\n",
       "      <td>1.670713e-05</td>\n",
       "      <td>1.114089e-05</td>\n",
       "      <td>1.476612e-07</td>\n",
       "      <td>3.733805e-06</td>\n",
       "      <td>6.965225e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.947555e-06</td>\n",
       "      <td>5.452003e-06</td>\n",
       "      <td>1.832342e-06</td>\n",
       "      <td>7.336506e-07</td>\n",
       "      <td>1.131646e-05</td>\n",
       "      <td>1.071788e-03</td>\n",
       "      <td>2.876753e-05</td>\n",
       "      <td>1.144850e-06</td>\n",
       "      <td>2.916980e-05</td>\n",
       "      <td>1.224543e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.603493e-09</td>\n",
       "      <td>6.014030e-10</td>\n",
       "      <td>1.176476e-10</td>\n",
       "      <td>5.761473e-08</td>\n",
       "      <td>1.008474e-09</td>\n",
       "      <td>1.536633e-08</td>\n",
       "      <td>2.041168e-08</td>\n",
       "      <td>8.044219e-10</td>\n",
       "      <td>1.615021e-09</td>\n",
       "      <td>8.323935e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   corner  overheard  size  lazili  camersa  apia  bumper  world  greenish  \\\n",
       "0       0          0     0       0        0     0       0      0         0   \n",
       "1       0          0     0       0        0     0       0      0         0   \n",
       "2       0          0     0       0        0     0       0      0         0   \n",
       "3       0          0     0       0        0     0       0      0         0   \n",
       "4       0          0     0       0        0     0       0      0         0   \n",
       "\n",
       "   fom      ...                991           992           993           994  \\\n",
       "0    0      ...       4.147876e-09  7.795882e-07  2.137072e-08  4.536942e-07   \n",
       "1    0      ...       1.153486e-06  2.155777e-08  7.707900e-08  1.716825e-08   \n",
       "2    0      ...       3.043387e-07  4.378452e-07  3.107051e-07  4.795648e-07   \n",
       "3    0      ...       2.947555e-06  5.452003e-06  1.832342e-06  7.336506e-07   \n",
       "4    0      ...       1.603493e-09  6.014030e-10  1.176476e-10  5.761473e-08   \n",
       "\n",
       "            995           996           997           998           999  \\\n",
       "0  2.348028e-07  1.146491e-06  1.363482e-06  1.078203e-08  1.252444e-07   \n",
       "1  6.402719e-08  3.399505e-07  2.291550e-07  8.842370e-09  4.936724e-07   \n",
       "2  1.099367e-06  1.670713e-05  1.114089e-05  1.476612e-07  3.733805e-06   \n",
       "3  1.131646e-05  1.071788e-03  2.876753e-05  1.144850e-06  2.916980e-05   \n",
       "4  1.008474e-09  1.536633e-08  2.041168e-08  8.044219e-10  1.615021e-09   \n",
       "\n",
       "           1000  \n",
       "0  3.330733e-09  \n",
       "1  4.335200e-07  \n",
       "2  6.965225e-06  \n",
       "3  1.224543e-05  \n",
       "4  8.323935e-10  \n",
       "\n",
       "[5 rows x 7456 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFeatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reducing dimensions of Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduceDimensions(x,ncomp):\n",
    "    #ncomp = number of components\n",
    "    pca = PCA(ncomp)\n",
    "    pca.fit(x)\n",
    "    newX = pca.transform(x)\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageMatrix = softMaxDF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.69051789e-07,   1.57853699e-06,   9.32865186e-05, ...,\n",
       "          5.88929013e-07,   1.14142540e-05,   3.70021713e-05],\n",
       "       [  4.46757322e-06,   5.97130207e-06,   1.52917948e-08, ...,\n",
       "          1.11132751e-06,   1.35697696e-04,   1.28081728e-06]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageMatrix[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageMatrix = softMaxDF.values\n",
    "imagePCAArray= reduceDimensions(imageMatrix,200) #PCA rray\n",
    "PCAimageDF = pd.DataFrame(imagePCAArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCAimageDF = pd.DataFrame(imagePCAArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006241</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>-0.004926</td>\n",
       "      <td>-0.008557</td>\n",
       "      <td>-0.011236</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>-0.008824</td>\n",
       "      <td>-0.009371</td>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>-0.005103</td>\n",
       "      <td>-0.024609</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>-0.002087</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.010897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006603</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>-0.011997</td>\n",
       "      <td>-0.011005</td>\n",
       "      <td>-0.022990</td>\n",
       "      <td>-0.005486</td>\n",
       "      <td>-0.027494</td>\n",
       "      <td>-0.026032</td>\n",
       "      <td>-0.029964</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003669</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>-0.002796</td>\n",
       "      <td>-0.004909</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011182</td>\n",
       "      <td>-0.024934</td>\n",
       "      <td>-0.021987</td>\n",
       "      <td>-0.024327</td>\n",
       "      <td>-0.031752</td>\n",
       "      <td>-0.143728</td>\n",
       "      <td>0.155639</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.059129</td>\n",
       "      <td>0.366964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>-0.001189</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>-0.002460</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004046</td>\n",
       "      <td>-0.015166</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>-0.006536</td>\n",
       "      <td>-0.016325</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>-0.014517</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>-0.002242</td>\n",
       "      <td>0.025167</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>-0.006373</td>\n",
       "      <td>-0.017161</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.016785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064056</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>-0.006395</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>-0.013124</td>\n",
       "      <td>-0.011271</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>-0.004227</td>\n",
       "      <td>-0.001720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.006241  0.005311 -0.004926 -0.008557 -0.011236  0.005487 -0.008824   \n",
       "1 -0.006603 -0.014573 -0.011997 -0.011005 -0.022990 -0.005486 -0.027494   \n",
       "2 -0.011182 -0.024934 -0.021987 -0.024327 -0.031752 -0.143728  0.155639   \n",
       "3  0.004046 -0.015166  0.009521 -0.006536 -0.016325  0.000412 -0.014517   \n",
       "4  0.064056  0.025218 -0.006395 -0.002476 -0.009404 -0.001485 -0.013124   \n",
       "\n",
       "        7         8         9      ...          190       191       192  \\\n",
       "0 -0.009371  0.005629  0.000342    ...     0.001889 -0.005103 -0.024609   \n",
       "1 -0.026032 -0.029964  0.000023    ...    -0.003669  0.003740  0.001544   \n",
       "2  0.021238  0.059129  0.366964    ...     0.001804  0.000683 -0.001189   \n",
       "3 -0.012316  0.005579  0.000069    ...     0.006581 -0.002242  0.025167   \n",
       "4 -0.011271  0.005274 -0.000106    ...    -0.002406  0.000676  0.000201   \n",
       "\n",
       "        193       194       195       196       197       198       199  \n",
       "0  0.003865 -0.010487  0.024255 -0.002087  0.002725  0.002498  0.010897  \n",
       "1 -0.002796 -0.004909  0.003404 -0.002496  0.001943 -0.000442  0.002209  \n",
       "2 -0.000918 -0.002460 -0.000426  0.001843  0.000703  0.002106  0.000565  \n",
       "3  0.004768 -0.006373 -0.017161 -0.011819 -0.005438  0.015707  0.016785  \n",
       "4 -0.000424  0.001275 -0.001002  0.001605 -0.000769 -0.004227 -0.001720  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCAimageDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allFeaturesRedNorm = pd.concat([normalizedDescVector, PCAimageDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allFeaturesRed = pd.concat([descVectors, PCAimageDF], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take top 40 image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probSum=softMaxDF.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probSumList = probSum.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colsToKeep = []\n",
    "for i in range(len(probSumList)):\n",
    "    if probSumList[i] > 40:\n",
    "#         print(\"column:\" , i+1 , x[i])\n",
    "        colsToKeep.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "condensImageDF = softMaxDF[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 54)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensImageDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allFeaturesCondensNorm = pd.concat([normalizedDescVector, condensImageDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allFeaturesCondensNorm = pd.concat([descVectors, condensImageDF], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 500 # 1st layer num features\n",
    "n_hidden_2 = 500 # 2nd layer num features\n",
    "n_input = allFeatures.shape[1]\n",
    "n_classes = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFeatures.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    #Hidden layer1 with RELU activation\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) \n",
    "    #Hidden layer2 with RELU activation\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])) \n",
    "    return tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "# Softmax loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) \n",
    "# Adam Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, features, labels):\n",
    "        self._features = features\n",
    "        self._labels = labels\n",
    "        self._num_examples = labels.shape[0]\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self._features\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed \n",
    "    def next_batch(self, batch_size):\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._features = self._features[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._features[start:end].astype(float), self._labels[start:end].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitData(data, labels):\n",
    "    num_train = 5000\n",
    "    num_val = 3000\n",
    "    num_test = 2000\n",
    "    train_data = data[:num_train]\n",
    "    train_labels = labels[:num_train]\n",
    "    val_data = data[num_train:num_train+num_val]\n",
    "    val_labels = labels[num_train:num_train+num_val]\n",
    "    test_data = data[num_train+num_val:]\n",
    "    test_labels = labels[num_train+num_val:]\n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = splitData (allFeatures.values, tagVectors.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 7456), (5000, 80), (3000, 7456), (3000, 80), (2000, 7456), (2000, 80))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape, val_data.shape, val_labels.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the data inti the class DataSets\n",
    "# data_sets = DataSet()\n",
    "data_sets_train = DataSet(train_data, train_labels)\n",
    "data_sets_validation = DataSet(val_data, val_labels)\n",
    "data_sets_test = DataSet(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100, 80) for Tensor 'Placeholder_1:0', which has shape '(?, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-620aeaf38ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Fit training using batch data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Compute average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    554\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (100, 80) for Tensor 'Placeholder_1:0', which has shape '(?, 2)'"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(data_sets_train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            # Load a new batch from train set\n",
    "            batch_xs, batch_ys = data_sets_train.next_batch(batch_size)\n",
    "            \n",
    "            # Fit training using batch data\n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    # Get prediction probabilities \n",
    "    predict_probability = tf.nn.softmax(pred)[:, 1]\n",
    "    \n",
    "    # Evaluate with test data\n",
    "    total_batch_tst = int(data_sets_test.num_examples/batch_size)\n",
    "    #avg_accuracy = 0.\n",
    "    \n",
    "    predictproba = np.zeros(data_sets_test.num_examples)\n",
    "    for i in range(total_batch_tst):\n",
    "        # Load a new batch from test set\n",
    "        batch_xs_tst, batch_ys_tst = data_sets_test.next_batch(batch_size)\n",
    "        #avg_accuracy += accuracy.eval({x: batch_xs_tst, y: batch_ys_tst})/total_batch_tst\n",
    "        #avg_accuracy += sess.run(accuracy, feed_dict={x: batch_xs_tst, y: batch_ys_tst})/total_batch_tst\n",
    "        \n",
    "        predictproba[i*batch_size : (i+1)*batch_size] = predict_probability.eval({x: batch_xs_tst, y: batch_ys_tst})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test Description Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDescVectors = binaryVectorizeDescriptions(numTest,descriptionTestFolder,indexedDescBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizedTestDescVector =testDescVectors.div(testDescVectors.sum(axis=1), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (normalizedDescVector.shape,tagVectors.shape,normalizedTestDescVector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features_df  = cleanImageFeatures(\"../../final/data/features_test/features_resnet1000_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.787713e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.082508e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>6.326978e-07</td>\n",
       "      <td>2.368942e-06</td>\n",
       "      <td>6.305951e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>3.289636e-06</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>7.752077e-07</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>3.737710e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.992100e-04</td>\n",
       "      <td>1.325652e-05</td>\n",
       "      <td>6.158723e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>8.189401e-06</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>1.162106e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.963639e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.046373e-06</td>\n",
       "      <td>7.960216e-07</td>\n",
       "      <td>1.174392e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>2.569785e-06</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>6.085262e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.307517e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.351767e-06</td>\n",
       "      <td>6.359755e-06</td>\n",
       "      <td>1.501927e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2.049569e-06</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.300293e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.445326e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537307e-04</td>\n",
       "      <td>2.446943e-06</td>\n",
       "      <td>8.829573e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>3.782963e-07</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6     \\\n",
       "523   0.000004  0.000020  0.000005  0.000005  0.000008  0.000009   \n",
       "1485  0.000048  0.000004  0.000011  0.000019  0.000010  0.000050   \n",
       "798   0.000177  0.000006  0.000019  0.000009  0.000296  0.000209   \n",
       "1910  0.000013  0.000058  0.000009  0.000007  0.000027  0.000093   \n",
       "765   0.000012  0.000999  0.000004  0.000006  0.000005  0.000078   \n",
       "\n",
       "              7         8         9             10      ...             991   \\\n",
       "523   1.787713e-07  0.000004  0.000002  7.082508e-07    ...     6.326978e-07   \n",
       "1485  7.752077e-07  0.000039  0.000026  3.737710e-05    ...     1.992100e-04   \n",
       "798   1.162106e-05  0.000003  0.000002  1.963639e-06    ...     2.046373e-06   \n",
       "1910  6.085262e-06  0.000019  0.000004  6.307517e-06    ...     5.351767e-06   \n",
       "765   1.300293e-06  0.000005  0.000017  5.445326e-07    ...     1.537307e-04   \n",
       "\n",
       "              992           993       994       995       996       997   \\\n",
       "523   2.368942e-06  6.305951e-06  0.000008  0.000011  0.000070  0.000185   \n",
       "1485  1.325652e-05  6.158723e-06  0.000024  0.000009  0.000313  0.000046   \n",
       "798   7.960216e-07  1.174392e-06  0.000008  0.000006  0.000017  0.000214   \n",
       "1910  6.359755e-06  1.501927e-06  0.000008  0.000008  0.000013  0.000079   \n",
       "765   2.446943e-06  8.829573e-07  0.000003  0.000001  0.000010  0.000014   \n",
       "\n",
       "              998       999       1000  \n",
       "523   3.289636e-06  0.000068  0.000019  \n",
       "1485  8.189401e-06  0.000245  0.000044  \n",
       "798   2.569785e-06  0.000198  0.000255  \n",
       "1910  2.049569e-06  0.000064  0.000007  \n",
       "765   3.782963e-07  0.000157  0.000115  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_images= pd.concat([softMaxDF, test_features_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1000)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageMatrix_train_test = train_test_images.values\n",
    "imagePCAArray_train_test= reduceDimensions(imageMatrix_train_test,200) #PCA Array\n",
    "PCAimageDF_train_test = pd.DataFrame(imagePCAArray_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 200)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCAimageDF_train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_PCA = PCAimageDF_train_test.tail(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_PCA = PCAimageDF_train_test.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 200), (10000, 200))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_PCA.shape, train_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6456)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDescVectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allFeaturesRedTrain = pd.concat([descVectors, train_PCA], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trampolin</th>\n",
       "      <th>crust</th>\n",
       "      <th>overgrowth</th>\n",
       "      <th>kitten</th>\n",
       "      <th>goblet</th>\n",
       "      <th>inform</th>\n",
       "      <th>martini</th>\n",
       "      <th>itsef</th>\n",
       "      <th>horserac</th>\n",
       "      <th>reb</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-7.494721e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031622</td>\n",
       "      <td>0.089936</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.152457</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.037399</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017319</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>1.690219e-02</td>\n",
       "      <td>0.016158</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>0.016535</td>\n",
       "      <td>0.015944</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.016277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334817</td>\n",
       "      <td>-0.247824</td>\n",
       "      <td>-0.216280</td>\n",
       "      <td>-2.594254e-01</td>\n",
       "      <td>-0.244885</td>\n",
       "      <td>-0.244189</td>\n",
       "      <td>-0.183010</td>\n",
       "      <td>-0.227677</td>\n",
       "      <td>-0.229170</td>\n",
       "      <td>-0.210246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002050</td>\n",
       "      <td>-0.002535</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>-2.568982e-03</td>\n",
       "      <td>-0.002734</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>-0.002630</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>-0.002520</td>\n",
       "      <td>-0.002832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>4.461040e-07</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>2.016778e-03</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.002039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379842</td>\n",
       "      <td>0.355091</td>\n",
       "      <td>0.236224</td>\n",
       "      <td>2.853546e-01</td>\n",
       "      <td>0.252347</td>\n",
       "      <td>0.202611</td>\n",
       "      <td>0.441237</td>\n",
       "      <td>0.289240</td>\n",
       "      <td>0.382725</td>\n",
       "      <td>0.234636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 6656 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          trampolin         crust  overgrowth        kitten        goblet  \\\n",
       "count  10000.000000  10000.000000  10000.0000  10000.000000  10000.000000   \n",
       "mean       0.000400      0.003500      0.0001      0.007700      0.000200   \n",
       "std        0.031622      0.089936      0.0100      0.152457      0.014141   \n",
       "min        0.000000      0.000000      0.0000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.0000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.0000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.0000      0.000000      0.000000   \n",
       "max        3.000000      4.000000      1.0000      5.000000      1.000000   \n",
       "\n",
       "             inform     martini       itsef    horserac         reb  \\\n",
       "count  10000.000000  10000.0000  10000.0000  10000.0000  10000.0000   \n",
       "mean       0.001200      0.0001      0.0001      0.0001      0.0001   \n",
       "std        0.037399      0.0100      0.0100      0.0100      0.0100   \n",
       "min        0.000000      0.0000      0.0000      0.0000      0.0000   \n",
       "25%        0.000000      0.0000      0.0000      0.0000      0.0000   \n",
       "50%        0.000000      0.0000      0.0000      0.0000      0.0000   \n",
       "75%        0.000000      0.0000      0.0000      0.0000      0.0000   \n",
       "max        2.000000      1.0000      1.0000      1.0000      1.0000   \n",
       "\n",
       "           ...                190           191           192           193  \\\n",
       "count      ...       10000.000000  10000.000000  10000.000000  1.000000e+04   \n",
       "mean       ...           0.000094     -0.000019     -0.000010 -7.494721e-05   \n",
       "std        ...           0.017319      0.017434      0.016827  1.690219e-02   \n",
       "min        ...          -0.334817     -0.247824     -0.216280 -2.594254e-01   \n",
       "25%        ...          -0.002050     -0.002535     -0.002384 -2.568982e-03   \n",
       "50%        ...           0.000025     -0.000190      0.000096  4.461040e-07   \n",
       "75%        ...           0.002301      0.001680      0.002268  2.016778e-03   \n",
       "max        ...           0.379842      0.355091      0.236224  2.853546e-01   \n",
       "\n",
       "                194           195           196           197           198  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.000018     -0.000100     -0.000096     -0.000129     -0.000117   \n",
       "std        0.016158      0.016340      0.016535      0.015944      0.016388   \n",
       "min       -0.244885     -0.244189     -0.183010     -0.227677     -0.229170   \n",
       "25%       -0.002734     -0.003231     -0.002630     -0.002217     -0.002520   \n",
       "50%       -0.000142     -0.000195      0.000066     -0.000132      0.000006   \n",
       "75%        0.002365      0.002268      0.002550      0.001996      0.002258   \n",
       "max        0.252347      0.202611      0.441237      0.289240      0.382725   \n",
       "\n",
       "                199  \n",
       "count  10000.000000  \n",
       "mean       0.000143  \n",
       "std        0.016277  \n",
       "min       -0.210246  \n",
       "25%       -0.002832  \n",
       "50%       -0.000101  \n",
       "75%        0.002039  \n",
       "max        0.234636  \n",
       "\n",
       "[8 rows x 6656 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFeaturesRedTrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allFeaturesTest = pd.concat([testDescVectors, test_PCA], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr1 = train_PCA.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countNans1 = 0\n",
    "for x in arr1:\n",
    "    if x == True:\n",
    "        countNans1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr2 = test_PCA.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countNans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countNans2 = 0\n",
    "for y in arr2:\n",
    "    if y == True:\n",
    "        countNans2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countNans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trampolin</th>\n",
       "      <th>crust</th>\n",
       "      <th>overgrowth</th>\n",
       "      <th>kitten</th>\n",
       "      <th>goblet</th>\n",
       "      <th>inform</th>\n",
       "      <th>martini</th>\n",
       "      <th>itsef</th>\n",
       "      <th>horserac</th>\n",
       "      <th>reb</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>-0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172899</td>\n",
       "      <td>0.022361</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.016482</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.016184</td>\n",
       "      <td>0.016420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.241610</td>\n",
       "      <td>-0.180840</td>\n",
       "      <td>-0.122876</td>\n",
       "      <td>-0.141511</td>\n",
       "      <td>-0.190932</td>\n",
       "      <td>-0.147779</td>\n",
       "      <td>-0.186341</td>\n",
       "      <td>-0.284043</td>\n",
       "      <td>-0.120838</td>\n",
       "      <td>-0.224245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>-0.002461</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>-0.003001</td>\n",
       "      <td>-0.002689</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>-0.003274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.141712</td>\n",
       "      <td>0.242131</td>\n",
       "      <td>0.306115</td>\n",
       "      <td>0.313511</td>\n",
       "      <td>0.270096</td>\n",
       "      <td>0.305608</td>\n",
       "      <td>0.359405</td>\n",
       "      <td>0.225965</td>\n",
       "      <td>0.138293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 6656 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       trampolin        crust  overgrowth       kitten       goblet  \\\n",
       "count       2000  2000.000000        2000  2000.000000  2000.000000   \n",
       "mean           0     0.001000           0     0.011000     0.000500   \n",
       "std            0     0.031615           0     0.172899     0.022361   \n",
       "min            0     0.000000           0     0.000000     0.000000   \n",
       "25%            0     0.000000           0     0.000000     0.000000   \n",
       "50%            0     0.000000           0     0.000000     0.000000   \n",
       "75%            0     0.000000           0     0.000000     0.000000   \n",
       "max            0     1.000000           0     4.000000     1.000000   \n",
       "\n",
       "            inform  martini  itsef  horserac   reb     ...               190  \\\n",
       "count  2000.000000     2000   2000      2000  2000     ...       2000.000000   \n",
       "mean      0.001000        0      0         0     0     ...         -0.000471   \n",
       "std       0.044721        0      0         0     0     ...          0.015836   \n",
       "min       0.000000        0      0         0     0     ...         -0.241610   \n",
       "25%       0.000000        0      0         0     0     ...         -0.002441   \n",
       "50%       0.000000        0      0         0     0     ...         -0.000054   \n",
       "75%       0.000000        0      0         0     0     ...          0.002155   \n",
       "max       2.000000        0      0         0     0     ...          0.109400   \n",
       "\n",
       "               191          192          193          194          195  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.000094     0.000052     0.000375    -0.000090     0.000498   \n",
       "std       0.014583     0.017054     0.016482     0.019342     0.018107   \n",
       "min      -0.180840    -0.122876    -0.141511    -0.190932    -0.147779   \n",
       "25%      -0.002461    -0.002694    -0.002420    -0.002777    -0.003001   \n",
       "50%      -0.000190     0.000013     0.000057    -0.000186    -0.000013   \n",
       "75%       0.001699     0.002218     0.002144     0.002308     0.002579   \n",
       "max       0.141712     0.242131     0.306115     0.313511     0.270096   \n",
       "\n",
       "               196          197          198          199  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  \n",
       "mean      0.000479     0.000643     0.000585    -0.000715  \n",
       "std       0.016686     0.018727     0.016184     0.016420  \n",
       "min      -0.186341    -0.284043    -0.120838    -0.224245  \n",
       "25%      -0.002689    -0.001885    -0.002415    -0.003274  \n",
       "50%       0.000275     0.000023    -0.000030    -0.000209  \n",
       "75%       0.002700     0.002190     0.002439     0.001794  \n",
       "max       0.305608     0.359405     0.225965     0.138293  \n",
       "\n",
       "[8 rows x 6656 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFeaturesTest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 6656), (10000, 80), (4000, 6656))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFeaturesRedTrain.shape, tagVectors.shape, allFeaturesTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-8eaf58fb616b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestPreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallFeaturesRedTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtagVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallFeaturesTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-200-ae50f1fb3f12>\u001b[0m in \u001b[0;36mlogRegression\u001b[0;34m(train, trainLabel, test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_predict_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# probabilities of the positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "testPreds = logRegression(allFeaturesRedTrain.values,tagVectors.values,allFeaturesTest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (testPreds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test Tag Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testTagVectors = getTagVectors(numTest,tagsTestFolder,indexedTagBag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use kNN to find the 20 closest tag vectors for each test prediction vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kNN(tags,k,preds):\n",
    "    model = NearestNeighbors(n_neighbors= k , algorithm='kd_tree').fit(tags)\n",
    "    dist,idxs = model.kneighbors(preds)\n",
    "    return dist,idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist,preds = kNN(testTagVectors,20,testPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveResults(res,name):\n",
    "    f = open(name,'w')\n",
    "    f.write('Descritpion_ID,Top_20_Image_IDs\\n')\n",
    "    for i in range(2000):\n",
    "        f.write(str(i)+'.txt,')\n",
    "        for j in range(20):\n",
    "            if j == 19:\n",
    "                f.write(str(res[i,j])+'.jpg\\n')\n",
    "            else:\n",
    "                f.write(str(res[i,j])+'.jpg ')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saveResults(preds,\"log+images+kNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
