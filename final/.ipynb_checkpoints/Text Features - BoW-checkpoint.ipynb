{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import re\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptionTrainFolder = \"/Users/francescoperera/Desktop/data/descriptions_train\"\n",
    "featuresTrainFolder = \"/Users/francescoperera/Desktop/data/features_train\"\n",
    "imagesTrainFolder = \"/Users/francescoperera/Desktop/data/images_train\"\n",
    "tagsTrainFolder = \"/Users/francescoperera/Desktop/data/tags_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptionTestFolder = \"/Users/francescoperera/Desktop/data/descriptions_test\"\n",
    "featuresTestFolder = \"/Users/francescoperera/Desktop/data/features_test\"\n",
    "imagesTestFolder = \"/Users/francescoperera/Desktop/data/images_test\"\n",
    "tagsTestFolder = \"/Users/francescoperera/Desktop/data/tags_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numTrain = 10000\n",
    "numTest = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTagsFile(fileName):\n",
    "    tags = []\n",
    "    f = open(fileName,\"r\")\n",
    "    for line in f:\n",
    "        line = line.split(\":\") # possibly also consider using the keys in each line(vehicle,outdoor etc..)\n",
    "        tag = line[-1].replace(\"\\n\",\"\")\n",
    "        tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "def readDescriptionFile(fileName):\n",
    "    desc = []\n",
    "    f = open(fileName,\"r\")\n",
    "    for line in f:\n",
    "        noPuncSentence = stripPunctuation(line.replace(\"\\n\",\"\"))\n",
    "        desc.append(noPuncSentence)\n",
    "    return desc\n",
    "    \n",
    "def stripPunctuation(s):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    return regex.sub(' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = readTagsFile(tagsTrainFolder +\"/0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descriptions = readDescriptionFile(descriptionTrainFolder + \"/0.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Descriptions with stemming and POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stemmedDescriptions(lst):\n",
    "    stemmedDescriptions = []\n",
    "    for line in lst:\n",
    "        posLine = pos(line.split(\" \"))\n",
    "        #print posLine\n",
    "        stemmedDescriptions.append(stemmer(posLine))\n",
    "    return stemmedDescriptions\n",
    "\n",
    "def stemmer(line):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmedLine = []\n",
    "    for word,pos in line:\n",
    "        if pos == \"NN\": # only stem nouns\n",
    "            stem = stemmer.stem(word)\n",
    "            stemmedLine.append(stem)\n",
    "    return stemmedLine \n",
    "\n",
    "def pos(line):\n",
    "    return pos_tag(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'skateboard', u'show', u'tabl', u'stage'], [u'skateboard', u'tabl', u''], [u'man', u'skateboard', u''], [u'skate', u'boarder', u'trick', u'tabl', u''], [u'person', u'skateboard', u'tabl', u'crowd', u'']]\n",
      "['The skateboarder is putting on a show using the picnic table as his stage ', 'A skateboarder pulling tricks on top of a picnic table ', 'A man riding on a skateboard on top of a table ', 'A skate boarder doing a trick on a picnic table ', 'A person is riding a skateboard on a picnic table with a crowd watching ']\n"
     ]
    }
   ],
   "source": [
    "stemDescriptions = stemmedDescriptions(descriptions)\n",
    "print stemDescriptions\n",
    "print descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemTags(lst):\n",
    "    newTags = []\n",
    "    for word in lst:\n",
    "        stem = PorterStemmer().stem(word)\n",
    "        newTags.append(stem)\n",
    "    return newTags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'airplan', u'bench', u'skateboard', u'person', u'truck', u'backpack', u'handbag', u'dining t']\n"
     ]
    }
   ],
   "source": [
    "print stemTags(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createBag(num,descFolder):\n",
    "    bag = {}\n",
    "    for n in range(num):\n",
    "        f = descFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileDesc = readDescriptionFile(f)\n",
    "        stemDescriptions = stemmedDescriptions(fileDesc)\n",
    "        for desc in stemDescriptions:\n",
    "            for word in desc: #word is in unicode, convert it to string with str()\n",
    "                if str(word) not in bag.keys():\n",
    "                    bag[str(word)] = 0\n",
    "    return bag\n",
    "\n",
    "def indexBag(bag):\n",
    "    idx = 0\n",
    "    for tag in bag.keys():\n",
    "        bag[tag] = idx\n",
    "        idx+=1\n",
    "    return bag\n",
    "\n",
    "def wordFrequency(num,descFolder,bag):\n",
    "    featureVectorList = []\n",
    "    for n in range(num):\n",
    "        imageFeatureVec = [0.0 for tag in range(len(bag.keys()))]\n",
    "        f = descFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileDescriptions = readDescriptionFile(f) #2D Array\n",
    "        stemDescriptions = stemmedDescriptions(fileDescriptions)\n",
    "        for desc in stemDescriptions:\n",
    "            for word in desc:\n",
    "                if str(word) in bag.keys():\n",
    "                    imageFeatureVec[bag[str(word)]] +=1.0\n",
    "        featureVectorList.append(imageFeatureVec)\n",
    "        \n",
    "        if n % 100 == 0 :\n",
    "            print \"file \" + str(n)\n",
    "\n",
    "    return pd.DataFrame(featureVectorList,columns = bag.keys())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTagVectorIdxs(num,tagFolder):\n",
    "    tagIdx = {}\n",
    "    idx = 0\n",
    "    for n in range(num):\n",
    "        f = descFolder +\"/\" + str(n) + \".txt\"\n",
    "        fileDesc = readTagsFile(f)\n",
    "        stemmedTags = stemTags(fileTags)\n",
    "        for tag in stemmedTags: #tag is unicode, use str() to remove unicode string\n",
    "            if str(tag) not in tagIdx.keys():\n",
    "                tagIdx[str(tag)] = idx\n",
    "                idx+=1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagOfWords = createBag(numTrain,descriptionTrainFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464\n"
     ]
    }
   ],
   "source": [
    "print len(bagOfWords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 0\n",
      "file 100\n",
      "file 200\n",
      "file 300\n",
      "file 400\n",
      "file 500\n",
      "file 600\n",
      "file 700\n",
      "file 800\n",
      "file 900\n",
      "file 1000\n",
      "file 1100\n",
      "file 1200\n",
      "file 1300\n",
      "file 1400\n",
      "file 1500\n",
      "file 1600\n",
      "file 1700\n",
      "file 1800\n",
      "file 1900\n",
      "file 2000\n",
      "file 2100\n",
      "file 2200\n",
      "file 2300\n",
      "file 2400\n",
      "file 2500\n",
      "file 2600\n",
      "file 2700\n",
      "file 2800\n",
      "file 2900\n",
      "file 3000\n",
      "file 3100\n",
      "file 3200\n",
      "file 3300\n",
      "file 3400\n",
      "file 3500\n",
      "file 3600\n",
      "file 3700\n",
      "file 3800\n",
      "file 3900\n",
      "file 4000\n",
      "file 4100\n",
      "file 4200\n",
      "file 4300\n",
      "file 4400\n",
      "file 4500\n",
      "file 4600\n",
      "file 4700\n",
      "file 4800\n",
      "file 4900\n",
      "file 5000\n",
      "file 5100\n",
      "file 5200\n",
      "file 5300\n",
      "file 5400\n",
      "file 5500\n",
      "file 5600\n",
      "file 5700\n",
      "file 5800\n",
      "file 5900\n",
      "file 6000\n",
      "file 6100\n",
      "file 6200\n",
      "file 6300\n",
      "file 6400\n",
      "file 6500\n",
      "file 6600\n",
      "file 6700\n",
      "file 6800\n",
      "file 6900\n",
      "file 7000\n",
      "file 7100\n",
      "file 7200\n",
      "file 7300\n",
      "file 7400\n",
      "file 7500\n",
      "file 7600\n",
      "file 7700\n",
      "file 7800\n",
      "file 7900\n",
      "file 8000\n",
      "file 8100\n",
      "file 8200\n",
      "file 8300\n",
      "file 8400\n",
      "file 8500\n",
      "file 8600\n",
      "file 8700\n",
      "file 8800\n",
      "file 8900\n",
      "file 9000\n",
      "file 9100\n",
      "file 9200\n",
      "file 9300\n",
      "file 9400\n",
      "file 9500\n",
      "file 9600\n",
      "file 9700\n",
      "file 9800\n",
      "file 9900\n"
     ]
    }
   ],
   "source": [
    "indexedBOW = indexBag(bagOfWords)\n",
    "vectorizedTrain = wordFrequency(numTrain,descriptionTrainFolder,indexedBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4464)\n"
     ]
    }
   ],
   "source": [
    "print vectorizedTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save  vectorizedTrain to file\n",
    "vectorizedTrain.to_csv(\"vectorizedTrain.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    normalizedDf = preprocessing.normalize(df, norm='l1')\n",
    "    return pd.DataFrame(normalizedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizedTrain = normalize(vectorizedTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4464)\n"
     ]
    }
   ],
   "source": [
    "print normalizedTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4454</th>\n",
       "      <th>4455</th>\n",
       "      <th>4456</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "      <th>4459</th>\n",
       "      <th>4460</th>\n",
       "      <th>4461</th>\n",
       "      <th>4462</th>\n",
       "      <th>4463</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   4454  \\\n",
       "0   0.2     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   4455  4456  4457  4458  4459  4460  4461  4462  4463  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[1 rows x 4464 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedTrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>disarray</th>\n",
       "      <th>mit</th>\n",
       "      <th>birdfeed</th>\n",
       "      <th>videogam</th>\n",
       "      <th>woodi</th>\n",
       "      <th>Night</th>\n",
       "      <th>all</th>\n",
       "      <th>yellow</th>\n",
       "      <th>sleek</th>\n",
       "      <th>...</th>\n",
       "      <th>baker</th>\n",
       "      <th>bathrob</th>\n",
       "      <th>fest</th>\n",
       "      <th>hiker</th>\n",
       "      <th>tankini</th>\n",
       "      <th>inset</th>\n",
       "      <th>emerg</th>\n",
       "      <th>fifti</th>\n",
       "      <th>sash</th>\n",
       "      <th>buoy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      disarray  mit  birdfeed  videogam  woodi  Night  all  yellow  sleek  \\\n",
       "0  4         0    0         0         0      0      0    0       0      0   \n",
       "\n",
       "   ...   baker  bathrob  fest  hiker  tankini  inset  emerg  fifti  sash  buoy  \n",
       "0  ...       0        0     0      0        0      0      0      0     0     0  \n",
       "\n",
       "[1 rows x 4464 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizedTrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
